package nnet;

/**
 * Интерфейс слоя обучаемого по алгоритму обратного распространения ошибки
 *
 * Интерфейс нейронного слоя обучаемого по алгоритму
 * обратного распространения ошибки.
 * Метод initAndSetRandomizeWeights задает начальные случайные значения весов в слое.
 * Метод computeBackwardError вычисляет ошибку в обратном направлении:
 * то есть ту, которая пришла на вход слоя от предыдущего слоя.
 * В качестве параметров computeBackwardError принимает входной вектор,
 * который подавался на вход и вектор ошибки для этого слоя.
 * Метод же adjust подгоняет веса нейроннов в сторону уменьшения ошибки.
 */
public interface BackpropLayer extends Layer {
    /**
     * Придает случайные значения весам нейронов
     * @param min Минимальное значение
     * @param max Максимальное значение
     */
    void randomize(float min,float max);

    /**
     * Выичисляет следующий вектор ошибки в обратном направлении
     * @param input Входной вектор
     * @param error Вектор ошибки
     * @return Следующий вектор ошибки в обратном направлении
     */
    float[] computeBackwardError(float[] input,float[] error);

    /**
     * Подгоняет веса нейронов в сторону уменьшения ошибки
     * @param input Входной вектор
     * @param error Вектор ошибки
     * @param rate Скорость обучения
     * @param momentum Моментум
     */
    void adjust(float[] input,float[] error,float rate,float momentum);
}
